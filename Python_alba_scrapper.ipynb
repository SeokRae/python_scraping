{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "os.system(\"clear\")\n",
    "alba_url = \"http://www.alba.co.kr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 Job 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 job_data 걸러내기\n",
    "def extract_jobs(goods):\n",
    "    \n",
    "    title = goods.find(\"td\", {\"class\": \"title\"})\n",
    "    title = title.find(\"a\", {\"class\": ''})\n",
    "    if title:\n",
    "        title = title.find(\"span\", {\"class\": \"company\"}).get_text().strip()\n",
    "    place = goods.find(\"td\", {\"class\": \"local\"})\n",
    "    if place:\n",
    "        place = place.get_text().strip().replace(\"\\xa0\", \" \")\n",
    "    # time\n",
    "    time = goods.find(\"td\", {\"class\": \"data\"})\n",
    "    work_time = time.find(\"span\", {\"class\": \"time\"})\n",
    "    if work_time:\n",
    "        work_time = work_time.get_text()\n",
    "    else:\n",
    "        work_time = time.find(\"span\", {\"class\": \"consult\"}).get_text()\n",
    "    # pay\n",
    "    pay_section = goods.find(\"td\", {\"class\": \"pay\"})\n",
    "    pay_unit, pay = pay_section.find_all(\"span\")\n",
    "\n",
    "    regdate = goods.find(\"td\", {\"class\": \"regDate\"}).get_text()\n",
    "    return {\n",
    "        \"place\": place,\n",
    "        \"title\": title,\n",
    "        \"time\": work_time,\n",
    "        \"pay\": f\"{pay_unit.get_text().strip()} {pay.get_text().strip()}\",\n",
    "        \"date\": regdate\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job List 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table의 table row 조회\n",
    "def get_jobs(link):\n",
    "    get_request = requests.get(link)\n",
    "    html_parse = bs(get_request.text, \"html.parser\")\n",
    "    goods_list = html_parse.find(\"div\", {\"class\": \"goodsList\"})\n",
    "    goods_body = goods_list.find(\"tbody\")\n",
    "    # summaryView 제외한 table_row 조회\n",
    "    goods_rows = goods_body.find_all(\"tr\", {\"class\": ['', 'divide']})\n",
    "    \n",
    "    jobs = []\n",
    "    if goods_rows:\n",
    "        for goods in goods_rows:\n",
    "            if len(goods.find_all('td')) == 1:\n",
    "                return ''\n",
    "            jobs.append(extract_jobs(goods))\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brand Info 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# { 'brand': [... jobs list] }\n",
    "def get_brand(brand):\n",
    "    brand_info = brand.find(\"a\", {\"class\": \"goodsBox-info\"})\n",
    "    brand_name = brand_info.find(\"span\", {\"class\": \"company\"}).get_text()\n",
    "    link = brand_info['href']\n",
    "    brand_data = {}\n",
    "    # jobs를 list로 반환\n",
    "    jobs = get_jobs(link)\n",
    "    # dict에 brand_name: jobs로 데이터 넣기\n",
    "    if jobs:\n",
    "        brand_data[brand_name] = jobs\n",
    "    return {\n",
    "        \"brand_data\": brand_data,\n",
    "        \"brand_name\": brand_name,\n",
    "        \"link\": link\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 알바 천국의 Brand List 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알바천국 페이지 호출\n",
    "def get_main_page():\n",
    "    brands = []\n",
    "    get_request = requests.get(alba_url)\n",
    "    if get_request.status_code:\n",
    "        html_parse = bs(get_request.text, \"html.parser\")\n",
    "        brand_main = html_parse.find(\"div\", {\"id\": \"MainSuperBrand\"})\n",
    "        brand_ul = brand_main.find(\"ul\", {\"class\": \"goodsBox\"})\n",
    "        brand_li = brand_ul.find_all(\"li\", {\"class\": \"impact\"})\n",
    "        \n",
    "        for idx, brand in enumerate(brand_li, start=1):\n",
    "            brand_summary = get_brand(brand)\n",
    "            if brand_summary.get('brand_data'):\n",
    "                print(f\"page: [{idx} / {len(brand_li)}] {brand_summary.get('brand_name')} Scrapping link:{brand_summary.get('link')}\")\n",
    "                brands.append(brand_summary.get('brand_data'))\n",
    "            else:\n",
    "                print(f\"page: [{idx} / {len(brand_li)}] ** 취업 정보가 존재하지 않습니다. {brand_summary.get('brand_name')} Scrapping link:{brand_summary.get('link')}\")\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    return brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Brand List to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장\n",
    "def save(brands):\n",
    "    for idx, brand in enumerate(brands, start = 1):\n",
    "        for file_name in brand.keys():\n",
    "            print(f\"[{idx}/{len(brands)}] 총 {len(brand[file_name])} 건 :: {file_name}\")\n",
    "            jobs = brand.get(file_name)\n",
    "            # csv 파일 만들기\n",
    "            file = open(f\"csv_file/{file_name}.csv\", mode=\"w\", newline=\"\")\n",
    "            # header\n",
    "            write = csv.writer(file)\n",
    "            header = [*jobs[0].keys()]\n",
    "            write.writerow(header)\n",
    "            # body data\n",
    "            for job in jobs:\n",
    "                write.writerow([*job.values()])\n",
    "    print(f\" 총 채용중인 브랜드 {len(brands)} 건\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로그램 실행 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: [1 / 89] ** 취업 정보가 존재하지 않습니다. 쉐이크쉑 Scrapping link:http://shakeshack.alba.co.kr/\n",
      "page: [2 / 89] 할리스커피 & 디초콜릿커피앤드 Scrapping link:http://hollys.alba.co.kr/\n",
      "page: [3 / 89] 엔제리너스 Scrapping link:http://angelinus.alba.co.kr/\n",
      "page: [4 / 89] 멕시카나 치킨 Scrapping link:http://mexicana.alba.co.kr/\n",
      "page: [5 / 89] (주)신세계 Scrapping link:http://shinsegae.alba.co.kr/\n",
      "page: [6 / 89] 홈플러스 익스프레스 Scrapping link:http://homeplusexpress.alba.co.kr/\n",
      "page: [7 / 89] ㈜썬앳푸드 시추안하우스,모락 Scrapping link:http://sunatfood.alba.co.kr/\n",
      "page: [8 / 89] 장원교육 Scrapping link:http://jangone.alba.co.kr/\n",
      "page: [9 / 89] 성원아이북랜드 Scrapping link:http://ibookland.alba.co.kr/\n",
      "page: [10 / 89] KFC Scrapping link:http://kfc.alba.co.kr/\n",
      "page: [11 / 89] 매드포갈릭 Scrapping link:http://madforgarlic.alba.co.kr/\n",
      "page: [12 / 89] 세븐일레븐 Scrapping link:http://7-eleven.alba.co.kr/\n",
      "page: [13 / 89] GS25 Scrapping link:http://gs25.alba.co.kr/\n",
      "page: [14 / 89] 아소비 Scrapping link:http://asobi.alba.co.kr/\n",
      "page: [15 / 89] 이랜드이츠 Scrapping link:http://www.alba.co.kr/job/brand/elandintro/\n",
      "page: [16 / 89] ㈜이마트 Scrapping link:http://emart.alba.co.kr/\n",
      "page: [17 / 89] 버거킹 Scrapping link:http://burgerking.alba.co.kr/\n",
      "page: [18 / 89] 경성주막1929 & 크라운호프 Scrapping link:http://pspfnd.alba.co.kr/\n",
      "page: [19 / 89] 더페이스샵 Scrapping link:http://tfs.alba.co.kr/\n",
      "page: [20 / 89] ㈜초록마을 Scrapping link:http://choroc.alba.co.kr/\n",
      "page: [21 / 89] 메쉬코리아 Scrapping link:http://vroong.alba.co.kr/\n",
      "page: [22 / 89] ** 취업 정보가 존재하지 않습니다. (주)후니에프앤비 Scrapping link:http://hdgaemi.alba.co.kr/\n",
      "page: [23 / 89] (주)제트콜 Scrapping link:http://zcall.alba.co.kr/\n",
      "page: [24 / 89] 웰스 Scrapping link:http://kyowonwells.alba.co.kr/\n",
      "page: [25 / 89] 제이디스포츠패션코리아 Scrapping link:http://jdsportsfashionkorea.alba.co.kr/\n",
      "page: [26 / 89] (주)대연-나이키공식판매점 Scrapping link:http://dae-yeon.alba.co.kr/\n",
      "page: [27 / 89] (주)하이엠솔루텍 Scrapping link:http://hcsmanager.alba.co.kr/\n",
      "page: [28 / 89] (주)에이비씨마트코리아 Scrapping link:http://abcmart.alba.co.kr/\n"
     ]
    }
   ],
   "source": [
    "# 프로그램 실행 함수\n",
    "def main():\n",
    "  \n",
    "    brands = get_main_page()\n",
    "    save(brands)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
